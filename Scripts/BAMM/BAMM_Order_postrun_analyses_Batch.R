rm(list=ls())
library("BAMMtools") 
library("coda")
library("geiger")

# assuming event data and mcmc out files generated by BAMM
# are store under folder named by each of 17 orders
# e.g. "working_dir/Rosales/Rosales_event_data_final.txt"
# e.g. "working_dir/Rosales/Rosales_mcmc_out_final.txt"


order.list <- c("Brassicales", "Celastrales", "Crossosomatales", "Cucurbitales", "Fabales", "Fagales", "Geraniales", "Huerteales", "Malpighiales", "Malvales", "Myrtales", "Oxalidales", "Picramniales", "Rosales", "Sapindales", "Zygophyllales", "Vitales")


for (i in 1:length(order.list)){
  
  tryCatch({
  Order <- order.list[i]
  dir.create(paste0(Order, "/result", sep=""))
  
  #read tree
  tree <- read.tree(paste(Order, "/", Order, "_4g.tre", sep=""))
  
  #BAMM object
  edata <- getEventData(tree, paste(Order, "/", Order, "_event_data_cmb.csv", sep=""), burnin = 0.1)
  saveRDS(edata, file=paste(Order, "/result/", Order, "_edata.rds", sep=""))
  #edata <- readRDS(file=paste(Order, "/", Order, "/result/", Order, "_edata.rds", sep=""))
  
  #Assessing MCMC convergence
  mcmc <- read.csv(paste(Order, "/", Order, "_mcmc_out_cmb.csv", sep=""), header=T)
  pdf(paste(Order, "/result/", Order, "_4g_MCMC_convergent.pdf", sep=""))
  plot(mcmc$logLik ~ mcmc$generation)
  dev.off()
  
  burnstart <- floor(0.1*nrow(mcmc))
  postburn <- mcmc[burnstart:nrow(mcmc), ]#postburn is the generations left after burning
  
  #next caculate the effective sample size (ESS), which should be greater than 200 if our analysis
  # ran long enough
  logLik <- effectiveSize(postburn$logLik) # calculates autocorrelation function
  N_shift <- effectiveSize(postburn$N_shift) #effective sample size on N-shifts
  ESSample <- cbind.data.frame(Order, logLik, N_shift)
  
  write.table(ESSample, "Rosids_4g_Order_ESS_convergence.txt", row.names=F, col.names=F, append=T, sep=",")
  
  #Bayes factors for model comparison
  postfile <- mcmc #since we already loaded this above
  bfmat <- computeBayesFactors(postfile, expectedNumberOfShifts = 1, burnin = 0.1)
  write.csv(bfmat, paste(Order, "/result/", Order,"_BF_matrix.csv", sep=""))
  stepBF <- stepBF(bfmat, step.size = 20)
  
  pdf(paste(Order, "/result/", Order,"_Prior_plot.pdf", sep=""))
  plotPrior(postfile, expectedNumberOfShifts=1)
  dev.off()
  
  
  # looking at the shift rates
  post_probs <- table(postburn$N_shifts) / nrow(postburn)
  names(post_probs)
  shift_probs <- summary(edata) #post_probs = shift_probs
  write.csv(shift_probs, paste(Order, "/result/", Order,"_shift_probs.csv", sep=""))
  
  
  #Bayesian credible sets of shift configurations
  css <- credibleShiftSet(edata, expectedNumberOfShifts=1, threshold=5, set.limit = 0.95)
  css$indices[[1]]
  css$number.distinct
  summary <- summary(css)
  
  saveRDS(css, file=paste(Order, "/result/", Order, "_credibleShiftSet.rds", sep=""))
  
  pdf(paste(Order, "/result/", Order,"_credible_shift_sets.pdf", sep=""))
  plot.credibleshiftset(css)
  dev.off()

  #Finding the single best shift configuration
  best <- getBestShiftConfiguration(edata, expectedNumberOfShifts=1, threshold = 5)
  
  saveRDS(best, file=paste(Order, "/result/", Order, "_BestShiftConfiguration.rds", sep=""))
  
  #pdf(paste(Order, "/result/", Order,"_BestShiftConfiguration.pdf", sep=""), width=8, height=11)
  pdf(paste(Order, "/result/", Order,"_BestShiftConfiguration.pdf", sep=""))
  plot.bammdata(best, lwd = 1, legend=T)
  branching.times(tree)
  addBAMMshifts(best, cex=1)
  axisPhylo()
  mtext(side=1, "Age (Myr)", adj=0, cex=0.8)
  dev.off()
  
  #making a rate through time plot with BAMMtools
  #ratetype If 'auto', defaults to speciation (for diversification) or beta (for traits). Can alternatively specify 'netdiv' or 'extinction'.
  pdf(paste(Order, "/result/", Order, "_SpeciationRateThroughTime_95.pdf", sep=""))
  plotRateThroughTime(edata, ratetype = "auto", useMedian=TRUE, intervals=c(0.05,0.95),
                      intervalCol='gray70', avgCol='blue', opacity=1)
  
  plotRateThroughTime(edata, ratetype = "netdiv", useMedian=TRUE, intervals=c(0.05,0.95),
                      intervalCol='gray70', avgCol='green', opacity=1, yline=0.1, cex.axis=0.8)
  
  plotRateThroughTime(edata, ratetype = "extinction", useMedian=TRUE, intervals=c(0.05,0.95),
                      intervalCol='gray70', avgCol='red', opacity=1)
  dev.off()
  
  
  #Plots a histogram of the frequency of rate values across the phylogeny.
  B.Project <- plot.bammdata(edata, show=F)
  saveRDS(B.Project, file=paste(Order, "/result/", Order, "_BAMM_Project.rds", sep=""))
  
  pdf(paste(Order, "/result/", Order,"_posterior_Histogram.pdf", sep=""))
  ratesHistogram(B.Project, plotBrks = F, xlab = "speciation rate", ylab = "density")
  dev.off()
  
  #write a function to extract node ID of where possible shifts occurred
  get_shift_location <- function(){
    Table.tmp <- as.data.frame(best$eventData)
    Node <- as.data.frame(best$eventData)$node
    Family <- NULL
    for(i in Node){
      
      list <- tips(tree, i)
      write.csv(list, file=paste(Order, "/result/", Order, i,"node_tips.txt", sep=""))
      
      Family <- c(Family, unlist(strsplit(list[1], "_"))[1])
    }
    
    Table <- cbind(Family, Table.tmp)
    
    write.csv(Table, paste(Order, "/result/", Order, "_possible_shift.csv", sep=""))
  }
  get_shift_location()
  
  rtt <- getRateThroughTimeMatrix(edata)
  saveRDS(rtt, paste(Order, "/result/", Order, "_RateThroughTimeMatrix.rds", sep=""))
  
  Age <- round(max(branching.times(tree)),2)
  MAP_configure_shifts <- length(as.data.frame(best$eventData)$node) - 1
  Matrix <- apply(rtt$lambda, 2, quantile, c(0.05, 0.5, 0.95))
  CI.5 <- round(mean(Matrix[1,]),2)
  CI.95 <- round(mean(Matrix[3,]),2)
  Mean <- round(mean(Matrix[2,]),2)
  Distinct_shifts <- css$number.distinct
  Core_shifts <- summary$Core_shifts[1]
  Core_shifts_Prob <- summary$probability[1]
  stepBF <- ifelse(is.na(stepBF[[1]]), NA, stepBF[[1]])
  results <- cbind.data.frame(Order, Age, Distinct_shifts, Core_shifts, Core_shifts_Prob, MAP_configure_shifts, stepBF, Mean, CI.5, CI.95)
  
  write.table(results, "Rosids_BAMM_4g_Order_results.txt", row.names=F, col.names=F, append=T, sep=",")
  
  ######################### Prepare Median Rate Matrix ##############################
  Median.lamda <- apply(rtt$lambda, 2, quantile,  c(0.5))
  Median.mu <- apply(rtt$mu, 2, quantile,  c(0.5))
  Median.netdiv <- Mean.lamda - Mean.mu
  
  Median.Rate.Matrix <- cbind.data.frame(rtt$times, Median.lamda, Median.mu, Median.netdiv)
  write.csv(Mean.Rate.Matrix, paste(Order, "/result/", Order, "_4g_Median_Rate_Matrix.csv", sep=""))
  })
  
}



